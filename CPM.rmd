---
title: "Stroke Clinical Predictive Model"
author: "Tosin Dairo"
date: "MARCH 27, 2020"
output:
  rmarkdown::github_document: default
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
tags:
- Health
- Predictive_Models
- Machine_Learning
categories: R
---
For easy reproducibility run [CPM.rmd](https://github.com/tosi-n/Stroke-CPM/blob/master/CPM.rmd)

## Clinical Predictive Model classifier for stroke

Stroke-CPM is a tool that takes information available about a patient and their observed predictive factors, and makes a prediction regarding their diagnosis and causal factors.

+ Diagnosis – detects presence of stroke currently
+ Causal Factors – assess whether observed predictive factor(s) is/are likely to be contributors to the development of stroke presently or in the future

<br></br>

#### Observed Factors:

+ Gender
+ Age
+ Hypertension
+ Heart Disease
+ Ever Married
+ Work Type
+ Residence Type
+ Average Glucose Level
+ BMI
+ Smoking Status

<br></br> 



```{r results='hide'}
{{knitr::spin_child('init.R')}}
```

Click [init.R](https://github.com/tosi-n/Stroke-CPM/blob/master/init.R) script to locate Rstudio environment setup and R package installation 


#### Python library import
```{python include=FALSE}
import matplotlib
matplotlib.use('TkAgg')
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```



```{r include=FALSE}
head(d)
```


#### Missing Values

```{r}
d$smoking_status <- na_if(d$smoking_status, "")
```



```{python}
print(r.d.isnull().sum())
fig, ax = plt.subplots(figsize=(14,12))
sns.heatmap(r.d.isnull(),yticklabels=False,cbar=False,cmap='viridis') 
```



```{r}
d$gender <- as.factor(d$gender)
d$ever_married <- as.factor(d$ever_married)
d$work_type <- as.factor(d$work_type)
d$Residence_type <- as.factor(d$Residence_type)
d$smoking_status <- as.factor(d$smoking_status)
str(d)
```
After checking for missing values, smoking status and bmi had missing values which could lead drawing an inaccurate inference about the stroke classification

#### Multiple Imputation for Missing Data
> To prevent bias in prediction, missing values are predicted and imputed into the stroke dataset  

Using MICE package, Predictive Mean Matching and Poly Regreession technique are used to imput data missing at random from smoking status and bmi

```{r results=FALSE}
imp <- mice(d, seed = 3333)
```



```{r}
imp$method
```



```{r results='hide'}
dx <- mice::complete(imp)
```



```{python include=FALSE}
print(r.dx.isnull().sum())
fig, ax = plt.subplots(figsize=(14,12))
sns.heatmap(r.dx.isnull(),yticklabels=False,cbar=False,cmap='viridis') 
```


#### Exploratory Analysis

Stroke class  from exploratory pairplot below shows imbalance in stroke outcome, hypertension predictor and heart.
Fitting a model on this imbalanced dataset would lead to overfitting whereby the trained model crams the train set data and predict wrongly on external datasets
```{python}
fig, ax = plt.subplots(figsize=(14,12))
sns.pairplot(r.dx)
plt.show()
```



```{python include=FALSE}
sns.countplot(x='stroke', data = r.dx)
plt.title("Stroke Class Distribution")
plt.show()
```



```{r results='hide'}
{{knitr::spin_child('label_encode.R')}}
```
Click [label_encode.R](https://github.com/tosi-n/Stroke-CPM/blob/master/label_encode.R) script to locate label encoder code


In order for us to predict the minority class in the imbalanced variable, the factor variables need to be encoded to vector types to enable prediction through oversampleing of minority class. 
```{r}
result <- encode.fit_transform(dx)

dx_ <- result[[2]]
# encode.transform()
```


>Checking proportion of imbalance in the below variables

```{r}
tab_df(table(dx_$stroke), title = "Stroke Class")
tab_df(table(dx_$hypertension), title = "Hypertension Class")
tab_df(table(dx_$heart_disease), title = "Heart Disease Class")
```



```{r results='hide'}
dx_$hypertension <- as.factor(dx_$hypertension)
dx_$heart_disease <- as.factor(dx_$heart_disease)
dx_$stroke <- as.factor(dx_$stroke)
dx_$gender <- as.factor(dx_$gender)
dx_$ever_married <- as.factor(dx_$ever_married)
dx_$work_type <- as.factor(dx_$work_type)
dx_$Residence_type <- as.factor(dx_$Residence_type)
dx_$smoking_status <- as.factor(dx_$smoking_status)
str(dx_)
```


#### Class Imbalance
To predict the minoritty class in stroke, the train set data is expose to SMOTE package inorder to use K-Nearest Neighbour for predicting miority class

```{r}
## Smote : Synthetic Minority Oversampling Technique To Handle Class Imbalancy In Binary Classification
set.seed(3333)

balanced_dx_ <-SMOTE(stroke ~., dx_, perc.over = 2100 , k = 5, perc.under = 160)

tab_df(table(balanced_dx_$stroke), title = "Stroke Class")


```


#### Cross Validation:
For good predictions of stroke, a model must be well calibrated and have high discrimination.
The input data  was divided into two groups, in order to fit the data in one group and validate it in the other.This helps to reducing training bias.
```{r}
# Random sample indexes
train_index <- sample(1:nrow(balanced_dx_), 0.8 * nrow(balanced_dx_))
test_index <- setdiff(1:nrow(balanced_dx_), train_index)

# Build X_train, X_test
X_train <- balanced_dx_[train_index, 2:12]

X_test <- balanced_dx_[test_index, 2:12]

```


#### Model Training - Logistic Regression
To classify patients who have stroke or do not have stroke and to check for contributing causal factors to stroke, a binary classifier is built to predict the cases of stroke. State-of-the-art binary classifier Logistic Regression is applied. 
As per the [TRIPOD](https://www.tripod-statement.org/Portals/0/Tripod%20Checklist%20Prediction%20Model%20Development%20and%20Validation%20PDF.pdf) guidelines, we would need to report this stroke clinical predictive model in sufficient detail to allow for reproducability on a totally dufferent dataset.
```{r results='hide'}
set.seed(3333)
model <- glm (stroke ~ ., data=X_train, family = binomial)
summary(model)
```
  

###### Selection of contributing causal factors to stroke
```{r results='hide'}
stepAIC(model, direction='both')
```



```{r}
model_select <- glm(formula = stroke ~ gender + age + hypertension + heart_disease + 
    ever_married + work_type + avg_glucose_level + smoking_status, 
    family = binomial, data = X_train)
summary(model_select)
```


Using the stepwise AIC technique, the trained model for stroke has dropped the variables BMI and Reesident Type as they are not contributing factors that would lead to stroke. Stroke classification is non-preedicttive from the above 2 variables, and they have non-significant p-values which are > 0.05. 


```{r}
## Predict the Values
predict <- predict(model, X_test, type = 'response')

## Create Confusion Matrix
table(X_test$stroke, predict > 0.5)
```

#### Discrimination of Logistic Regression Classifier
Using the Discrimination, we check if trained CPM has a simultaneously high sensitivity and specificity. A receiver operator characteristic (ROC) curve is ploted using sensitivity against ‘1-specificity’ across the full range of potential cutpoints at 93%.

```{r}
#ROCR Curve
ROCRpred <- prediction(predict, X_test$stroke)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
p <- plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
abline(a=0, b=1)
```
The ROC curve shows further to the top left of the graph, this indicates a great test.


```{r}
auc(roc(X_test$stroke ~ predict))

hoslem.test(x = X_test$stroke, y=predict, g=10)
```
To determine how far to the top left of the graph the curve is, the Area Under the Curve (AUC) is calculated

So the AUC for the Logistic Regression Classifier is 0.92 which represents a near perfect discrimination

#### Calibration of Logistic Regression Classifier
Calibration using Hosmer and Lemeshow goodness of fit test shows significant p-value which indicates model validity


#### Model Training - Random Forest 
To further check for a better prediction classifier, a Random Forest model is built check for contributing causal factors to stroke and also to classify patients who have stroke or do not have stroke.
As per the [TRIPOD](https://www.tripod-statement.org/Portals/0/Tripod%20Checklist%20Prediction%20Model%20Development%20and%20Validation%20PDF.pdf) guidelines, we would need to report this stroke clinical predictive model in sufficient detail to allow for reproducability on a totally dufferent dataset.

```{r results='hide'}
set.seed(3333)
rf = randomForest(stroke ~ ., 
                  ntree = 500,
                   data = X_train)
rf
plot(rf) 
```


###### Selection of contributing causal factors to stroke
```{r results='hide'}
varImp(rf)
```



```{r}
## Important variables according to the model
varImpPlot(rf,  
           sort = T,
           n.var=10,
           main="Variable Importance")
```

>After applying Random Forest classifier algorithm, all contributing causal factors were kept by the model and rated in order of importance as seen in the above plot


```{r}
predicted.response <- predict(rf, X_test)


confusionMatrix(data=predicted.response,  
                reference=X_test$stroke)
```

#### Discrimination of Random Forest Classifier
Using the Discrimination, we check if trained CPM has a simultaneously high sensitivity and specificity. A receiver operator characteristic (ROC) curve is ploted using sensitivity against ‘1-specificity’ across the full range of potential cutpoints at 88%.

```{r}
#ROCR Curve
ROCRpred_rf <- prediction(as.numeric(predicted.response), X_test$stroke)
ROCRperf_rf <- performance(ROCRpred_rf, 'tpr','fpr')
plot(ROCRperf_rf, colorize = TRUE, text.adj = c(-0.2,1.7))
abline(a=0, b=1)
```
The ROC curve shows further to the top left of the graph, this indicates a great test, but is slightly lower than the Logistic Regression Classifier.


```{r}

auc(roc(X_test$stroke ~ as.numeric(predicted.response)))

hoslem.test(x = X_test$stroke, y=as.numeric(predicted.response), g=10)

```
To determine how far to the top left of the graph the curve is, the Area Under the Curve (AUC) is calculated

So the AUC for the Random Forest classifier is 0.89 which represents a near perfect discrimination

#### Calibration of Logistic Regression Classifier
Calibration using Hosmer and Lemeshow goodness of fit test shows significant p-value which indicates model validity




```{r}

```



```{r}

```



```{r}

```



```{r}

```


#### Conclusion

Overall logistic regression was selected as the best model to predict if a patient can have stroke or not. To achieve this and reduce the potential of bias and oveerfitting of trained model, imbalanced data are sampled because it is a common hurdle in healthcare. 
Also performed multiple imputation to predict missing data of smoke status in other ways as well

