{
    "data" : [
        "head(d)",
        "> ",
        "imp <- mice(d, seed = 3333)",
        "\n iter imp variable\n  1   1  bmi\n  1   2  bmi\n  1   3  bmi\n  1   4  bmi\n  1   5  bmi\n  2   1  bmi\n  2   2  bmi\n  2   3  bmi\n  2   4  bmi\n  2   5  bmi\n  3   1  bmi\n  3   2  bmi\n  3   3  bmi\n  3   4  bmi\n  3   5  bmi\n  4   1  bmi\n  4   2  bmi\n  4   3  bmi\n  4   4  bmi\n  4   5  bmi\n  5   1  bmi\n  5   2  bmi\n  5   3  bmi\n  5   4  bmi\n  5   5  bmi\n",
        "> ",
        "",
        "> ",
        "tab_df(imp$data, title = \"WHERE IMPUTATION OCCURS WITHIN THE FULL DATASET\")",
        "\n",
        "> ",
        "imp <- mice(d, seed = 3333)",
        "\n iter imp variable\n  1   1  bmi\n  1   2  bmi\n  1   3  bmi\n  1   4  bmi\n  1   5  bmi\n  2   1  bmi\n  2   2  bmi\n  2   3  bmi\n  2   4  bmi\n  2   5  bmi\n  3   1  bmi\n  3   2  bmi\n  3   3  bmi\n  3   4  bmi\n  3   5  bmi\n  4   1  bmi\n  4   2  bmi\n  4   3  bmi\n  4   4  bmi\n  4   5  bmi\n  5   1  bmi\n  5   2  bmi\n  5   3  bmi\n  5   4  bmi\n  5   5  bmi\n",
        "> ",
        "",
        "> ",
        "tab_df(imp$where, title = \"WHERE IMPUTATION OCCURS WITHIN THE FULL DATASET\")",
        "Error: Argument 1 must have names\n",
        "> ",
        "str(d)",
        "'data.frame':\t43400 obs. of  12 variables:\n $ id               : int  30669 30468 16523 56543 46136 32257 52800 41413 15266 28674 ...\n $ gender           : Factor w/ 3 levels \"Female\",\"Male\",..: 2 2 1 1 2 1 1 1 1 1 ...\n $ age              : num  3 58 8 70 14 47 52 75 32 74 ...\n $ hypertension     : int  0 1 0 0 0 0 0 0 0 1 ...\n $ heart_disease    : int  0 0 0 0 0 0 0 1 0 0 ...\n $ ever_married     : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 2 2 2 2 2 ...\n $ work_type        : Factor w/ 5 levels \"children\",\"Govt_job\",..: ",
        "1 4 4 4 3 4 4 5 4 5 ...\n $ Residence_type   : Factor w/ 2 levels \"Rural\",\"Urban\": 1 2 2 1 1 2 2 1 1 2 ...\n $ avg_glucose_level: num  95.1 88 110.9 69 161.3 ...\n $ bmi              : num  18 39.2 17.6 35.9 19.1 50.1 17.7 27 32.3 54.6 ...\n $ smoking_status   : Factor w/ 4 levels \"\",\"formerly smoked\",..: 1 3 1 2 1 1 2 3 4 3 ...\n $ stroke           : int  0 0 0 0 0 0 0 0 0 0 ...\n\nRestarting R session...\n\n",
        "> ",
        "getwd()",
        "[1] \"/Volumes/Loopdisk/Stroke-CPM\"\n",
        "> ",
        "library(reticulate)",
        "> ",
        "library(mice)",
        "> ",
        "library(tidyverse)",
        "> ",
        "library(ggplot2)",
        "> ",
        "library(MASS)",
        "> ",
        "library(stargazer)",
        "> ",
        "library(sjPlot)",
        "> ",
        "use_python(\"/Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\", required = TRUE)",
        "> ",
        "d <- read.csv(\"/Volumes/Loopdisk/Stroke-CPM/data/train_2v.csv\")",
        "> ",
        "reticulate::py_config()",
        "python:         /Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\nlibpython:      /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/config-3.6m-darwin/libpython3.6.dylib\npythonhome:     /Library/Frameworks/Python.framework/Versions/3.6:/Library/Frameworks/Python.framework/Versions/3.6\nversion:        3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31)  [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\nnumpy:          /Volumes/Loopdisk/Dev/PyDsc/env/lib/python3.6/site-packages/numpy\nnumpy_version:  1.16.2\n\nNOTE: Python version was forced by use_python function\n",
        "> ",
        "getwd()",
        "[1] \"/Volumes/Loopdisk/Stroke-CPM\"\n",
        "> ",
        "library(reticulate)",
        "> ",
        "library(mice)",
        "> ",
        "library(tidyverse)",
        "> ",
        "library(ggplot2)",
        "> ",
        "library(MASS)",
        "> ",
        "library(stargazer)",
        "> ",
        "library(sjPlot)",
        "> ",
        "use_python(\"/Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\", required = TRUE)",
        "> ",
        "d <- read.csv(\"/Volumes/Loopdisk/Stroke-CPM/data/train_2v.csv\")",
        "> ",
        "reticulate::py_config()",
        "python:         /Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\nlibpython:      /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/config-3.6m-darwin/libpython3.6.dylib\npythonhome:     /Library/Frameworks/Python.framework/Versions/3.6:/Library/Frameworks/Python.framework/Versions/3.6\nversion:        3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31)  [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\nnumpy:          /Volumes/Loopdisk/Dev/PyDsc/env/lib/python3.6/site-packages/numpy\nnumpy_version:  1.16.2\n\nNOTE: Python version was forced by use_python function\n",
        "> ",
        "str(d)",
        "'data.frame':\t43400 obs. of  12 variables:\n $ id               : int  30669 30468 16523 56543 46136 32257 52800 41413 15266 28674 ...\n $ gender           : Factor w/ 3 levels \"Female\",\"Male\",..: 2 2 1 1 2 1 1 1 1 1 ...\n $ age              : num  3 58 8 70 14 47 52 75 32 74 ...\n $ hypertension     : int  0 1 0 0 0 0 0 0 0 1 ...\n $ heart_disease    : int  0 0 0 0 0 0 0 1 0 0 ...\n $ ever_married     : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 2 2 2 2 2 ...\n $ work_type        : Factor w/ 5 levels \"children\",\"Govt_job\",..: ",
        "1 4 4 4 3 4 4 5 4 5 ...\n $ Residence_type   : Factor w/ 2 levels \"Rural\",\"Urban\": 1 2 2 1 1 2 2 1 1 2 ...\n $ avg_glucose_level: num  95.1 88 110.9 69 161.3 ...\n $ bmi              : num  18 39.2 17.6 35.9 19.1 50.1 17.7 27 32.3 54.6 ...\n $ smoking_status   : Factor w/ 4 levels \"\",\"formerly smoked\",..: 1 3 1 2 1 1 2 3 4 3 ...\n $ stroke           : int  0 0 0 0 0 0 0 0 0 0 ...\n",
        "> ",
        "head(d)",
        "> ",
        "View(d)",
        "> ",
        "d$smoking_status <- na_if(d$smoking_status, \"none\")",
        "> ",
        "d$smoking_status <- na_if(d$smoking_status, \"\")",
        "> ",
        "d$gender <- as.factor(d$gender)",
        "> ",
        "d$ever_married <- as.factor(d$ever_married)",
        "> ",
        "d$work_type <- as.factor(d$work_type)",
        "> ",
        "d$Residence_type <- as.factor(d$Residence_type)",
        "> ",
        "d$smoking_status <- as.factor(d$smoking_status)",
        "> ",
        "str(d)",
        "'data.frame':\t43400 obs. of  12 variables:\n $ id               : int  30669 30468 16523 56543 46136 32257 52800 41413 15266 28674 ...\n $ gender           : Factor w/ 3 levels \"Female\",\"Male\",..: 2 2 1 1 2 1 1 1 1 1 ...\n $ age              : num  3 58 8 70 14 47 52 75 32 74 ...\n $ hypertension     : int  0 1 0 0 0 0 0 0 0 1 ...\n $ heart_disease    : int  0 0 0 0 0 0 0 1 0 0 ...\n $ ever_married     : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 2 2 2 2 2 ...\n $ work_type        : Factor w/ 5 levels \"children\",\"Govt_job\",..: ",
        "1 4 4 4 3 4 4 5 4 5 ...\n $ Residence_type   : Factor w/ 2 levels \"Rural\",\"Urban\": 1 2 2 1 1 2 2 1 1 2 ...\n $ avg_glucose_level: num  95.1 88 110.9 69 161.3 ...\n $ bmi              : num  18 39.2 17.6 35.9 19.1 50.1 17.7 27 32.3 54.6 ...\n $ smoking_status   : Factor w/ 4 levels \"\",\"formerly smoked\",..: NA 3 NA 2 NA NA 2 3 4 3 ...\n $ stroke           : int  0 0 0 0 0 0 0 0 0 0 ...\n",
        "> ",
        "imp <- mice(d, seed = 3333)",
        "\n iter imp variable\n  1   1  bmi  smoking_status\n  1   2  bmi  smoking_status\n  1   3  bmi  smoking_status\n  1   4  bmi  smoking_status\n  1   5  bmi  smoking_status\n  2   1  bmi  smoking_status\n  2   2  bmi  smoking_status\n  2   3  bmi  smoking_status\n  2   4  bmi  smoking_status\n  2   5  bmi  smoking_status\n  3   1  bmi  smoking_status\n  3   2  bmi  smoking_status\n  3   3  bmi  smoking_status\n  3   4  bmi  smoking_status\n  3   5  bmi  smoking_status\n  4   1  bmi  smoking_status\n  4   2  bmi  smoking_status",
        "\n  4   3  bmi  smoking_status\n  4   4  bmi  smoking_status\n  4   5  bmi  smoking_status\n  5   1  bmi  smoking_status\n  5   2  bmi  smoking_status\n  5   3  bmi  smoking_status\n  5   4  bmi  smoking_status\n  5   5  bmi  smoking_status\n",
        "> ",
        "",
        "> ",
        "tab_df(imp$where, title = \"WHERE IMPUTATION OCCURS WITHIN THE FULL DATASET\")",
        "Error: Argument 1 must have names\n",
        "> ",
        "imp <- mice(d, seed = 3333)",
        "\n iter imp variable\n  1   1  bmi  smoking_status\n  1   2  bmi  smoking_status\n  1   3  bmi  smoking_status\n  1   4  bmi  smoking_status\n  1   5  bmi  smoking_status\n  2   1  bmi  smoking_status\n  2   2  bmi  smoking_status\n  2   3  bmi  smoking_status\n  2   4  bmi  smoking_status\n  2   5  bmi  smoking_status\n  3   1  bmi  smoking_status\n  3   2  bmi  smoking_status\n  3   3  bmi  smoking_status\n  3   4  bmi  smoking_status\n  3   5  bmi  smoking_status\n  4   1  bmi  smoking_status\n  4   2  bmi  smoking_status",
        "\n  4   3  bmi  smoking_status\n  4   4  bmi  smoking_status\n  4   5  bmi  smoking_status\n  5   1  bmi  smoking_status\n  5   2  bmi  smoking_status\n  5   3  bmi  smoking_status\n  5   4  bmi  smoking_status\n  5   5  bmi  smoking_status\n",
        "> ",
        "",
        "> ",
        "imp$method",
        "               id            gender               age      hypertension     heart_disease \n               \"\"                \"\"                \"\"                \"\"                \"\" \n     ever_married         work_type    Residence_type avg_glucose_level               bmi \n               \"\"                \"\"                \"\"                \"\"             \"pmm\" \n   smoking_status            stroke \n        \"polyreg\"                \"\" \n",
        "> ",
        "dx <- mice::complete(imp)",
        "> ",
        "View(dx)",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(adult), 0.8 * nrow(dx))",
        "Error in nrow(adult) : object 'adult' not found\n",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(dx), 0.8 * nrow(dx))",
        "> ",
        "test_index <- setdiff(1:nrow(dx), train_index)",
        "> ",
        "",
        "> ",
        "# Build X_train, y_train, X_test, y_test",
        "> ",
        "X_train <- dx[train_index, -12]",
        "> ",
        "y_train <- dx[train_index, \"stroke\"]",
        "> ",
        "",
        "> ",
        "X_test <- dx[test_index, -12]",
        "> ",
        "y_test <- dx[test_index, \"stroke\"]",
        "> ",
        "View(X_train)",
        "> ",
        "View(X_train)",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "Error in one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE,  : \n  could not find function \"one_hot_encoder\"\n",
        "> ",
        "X_train <- dataPreparation::one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "Error in loadNamespace(name) : \n  there is no package called ‘dataPreparation’\n",
        "> ",
        "install.packages(\"dataPreparation\")",
        "Installing package into ‘/Users/tosi-n/Library/R/3.6/library’\n(as ‘lib’ is unspecified)\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/dataPreparation_0.4.3.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 1507230 bytes (1.4 MB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 1.4 MB\n\n",
        "\nThe downloaded binary packages are in\n\t/var/folders/1p/d4hfqy4d7kj4dl0jw737b9w00000gn/T//Rtmp9HQHJe/downloaded_packages\n",
        "> ",
        "getwd()",
        "[1] \"/Volumes/Loopdisk/Stroke-CPM\"\n",
        "> ",
        "library(reticulate)",
        "> ",
        "library(mice)",
        "> ",
        "library(tidyverse)",
        "> ",
        "library(ggplot2)",
        "> ",
        "library(MASS)",
        "> ",
        "library(stargazer)",
        "> ",
        "library(sjPlot)",
        "> ",
        "library(dataPreparation)",
        "> ",
        "use_python(\"/Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\", required = TRUE)",
        "> ",
        "d <- read.csv(\"/Volumes/Loopdisk/Stroke-CPM/data/train_2v.csv\")",
        "> ",
        "reticulate::py_config()",
        "python:         /Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\nlibpython:      /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/config-3.6m-darwin/libpython3.6.dylib\npythonhome:     /Library/Frameworks/Python.framework/Versions/3.6:/Library/Frameworks/Python.framework/Versions/3.6\nversion:        3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31)  [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\nnumpy:          /Volumes/Loopdisk/Dev/PyDsc/env/lib/python3.6/site-packages/numpy\nnumpy_version:  1.16.2\n\nNOTE: Python version was forced by use_python function\n",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "Error in one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE,  : \n  object 'encoding' not found\n",
        "> ",
        "X_train <- dataPreparation::one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "Error in dataPreparation::one_hot_encoder(dataSet = X_train, encoding = encoding,  : \n  object 'encoding' not found\n",
        "> ",
        "encoding <- build_encoding(dataSet = X_train, cols = \"auto\", verbose = TRUE)",
        "[1] \"build_encoding: I will compute encoding on 5 character and factor columns.\"\n[1] \"build_encoding: it took me: 0s to compute encoding for 5 character and factor columns.\"\n",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.01s to transform 5 column(s).\"\n",
        "> ",
        "X_test <- one_hot_encoder(dataSet = X_test, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.01s to transform 5 column(s).\"\n",
        "> ",
        "View(X_train)",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(dx), 0.8 * nrow(dx))",
        "> ",
        "test_index <- setdiff(1:nrow(dx), train_index)",
        "> ",
        "",
        "> ",
        "# Build X_train, y_train, X_test, y_test",
        "> ",
        "X_train <- dx[train_index, -12]",
        "> ",
        "y_train <- dx[train_index, \"stroke\"]",
        "> ",
        "",
        "> ",
        "X_test <- dx[test_index, -12]",
        "> ",
        "y_test <- dx[test_index, \"stroke\"]",
        "> ",
        "X_train = pd.get_dummies(r.X_train)",
        "Error in pd.get_dummies(r.X_train) : \n  could not find function \"pd.get_dummies\"\n",
        "> ",
        "View(X_train)",
        "> ",
        "encoding <- build_encoding(dataSet = X_train, cols = \"auto\", verbose = TRUE)",
        "[1] \"build_encoding: I will compute encoding on 5 character and factor columns.\"\n[1] \"build_encoding: it took me: 0s to compute encoding for 5 character and factor columns.\"\n",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.01s to transform 5 column(s).\"\n",
        "> ",
        "X_test <- one_hot_encoder(dataSet = X_test, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.01s to transform 5 column(s).\"\n",
        "> ",
        "View(X_test)",
        "> ",
        "py_install(\"sklearn\")",
        "Using virtual environment '~/.virtualenvs/r-reticulate' ...\nProcessing /Users/tosi-n/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074/sklearn-0.0-py2.py3-none-any.whl\nCollecting scikit-learn\n  Using cached scikit_learn-0.22.2.post1-cp37-cp37m-macosx_10_9_x86_64.whl (7.1 MB)\nCollecting joblib>=0.11\n  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\nCollecting scipy>=0.17.0\n  Using cached scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\nCollecting numpy>=1.11.0\n",
        "  Using cached numpy-1.18.2-cp37-cp37m-macosx_10_9_x86_64.whl (15.1 MB)\nInstalling collected packages: joblib, numpy, scipy, scikit-learn, sklearn\nSuccessfully installed joblib-0.14.1 numpy-1.18.2 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0\n",
        "> ",
        "py_install(\"imblearn\")",
        "Using virtual environment '~/.virtualenvs/r-reticulate' ...\nCollecting imblearn\n  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\nCollecting imbalanced-learn\n  Downloading imbalanced_learn-0.6.2-py3-none-any.whl (163 kB)\nCollecting joblib>=0.11\n  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\nCollecting numpy>=1.11\n  Using cached numpy-1.18.2-cp37-cp37m-macosx_10_9_x86_64.whl (15.1 MB)\nCollecting scipy>=0.17\n  Using cached scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\nCollecting scikit-learn>=0.22\n",
        "  Using cached scikit_learn-0.22.2.post1-cp37-cp37m-macosx_10_9_x86_64.whl (7.1 MB)\nInstalling collected packages: joblib, numpy, scipy, scikit-learn, imbalanced-learn, imblearn\nSuccessfully installed imbalanced-learn-0.6.2 imblearn-0.0 joblib-0.14.1 numpy-1.18.2 scikit-learn-0.22.2.post1 scipy-1.4.1\n",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(dx), 0.8 * nrow(dx))",
        "> ",
        "test_index <- setdiff(1:nrow(dx), train_index)",
        "> ",
        "",
        "> ",
        "# Build X_train, y_train, X_test, y_test",
        "> ",
        "X_train <- dx[train_index, -12]",
        "> ",
        "y_train <- dx[train_index, \"stroke\"]",
        "> ",
        "",
        "> ",
        "X_test <- dx[test_index, -12]",
        "> ",
        "y_test <- dx[test_index, \"stroke\"]",
        "> ",
        "library(data.table)",
        "> ",
        "X_train <- one_hot(X_train, dropCols=FALSE)",
        "Error in one_hot(X_train, dropCols = FALSE) : \n  could not find function \"one_hot\"\n",
        "> ",
        "library(data.table)",
        "> ",
        "X_train <- data.table::one_hot(X_train, dropCols=FALSE)",
        "Error: 'one_hot' is not an exported object from 'namespace:data.table'\n",
        "> ",
        "encoding <- build_encoding(dataSet = X_train, cols = c(\"gender\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"), verbose = TRUE)",
        "[1] \"build_encoding: I will compute encoding on 5 character and factor columns.\"\n[1] \"build_encoding: it took me: 0s to compute encoding for 5 character and factor columns.\"\n",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.02s to transform 5 column(s).\"\n",
        "> ",
        "X_test <- one_hot_encoder(dataSet = X_test, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.01s to transform 5 column(s).\"\n",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(dx), 0.8 * nrow(dx))",
        "> ",
        "test_index <- setdiff(1:nrow(dx), train_index)",
        "> ",
        "",
        "> ",
        "# Build X_train, y_train, X_test, y_test",
        "> ",
        "X_train <- dx[train_index, -12]",
        "> ",
        "y_train <- dx[train_index, \"stroke\"]",
        "> ",
        "",
        "> ",
        "X_test <- dx[test_index, -12]",
        "> ",
        "y_test <- dx[test_index, \"stroke\"]",
        "> ",
        "encoding <- build_encoding(dataSet = X_train, cols = \"auto\", verbose = TRUE)",
        "[1] \"build_encoding: I will compute encoding on 5 character and factor columns.\"\n[1] \"build_encoding: it took me: 0s to compute encoding for 5 character and factor columns.\"\n",
        "> ",
        "X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.02s to transform 5 column(s).\"\n",
        "> ",
        "X_test <- one_hot_encoder(dataSet = X_test, encoding = encoding, drop = TRUE, verbose = TRUE)",
        "[1] \"one_hot_encoder: I will one hot encode some columns.\"\n[1] \"one_hot_encoder: I am doing column: gender\"\n[1] \"one_hot_encoder: I am doing column: ever_married\"\n[1] \"one_hot_encoder: I am doing column: work_type\"\n[1] \"one_hot_encoder: I am doing column: Residence_type\"\n[1] \"one_hot_encoder: I am doing column: smoking_status\"\n[1] \"one_hot_encoder: It took me 0.02s to transform 5 column(s).\"\n",
        "> ",
        "# Random sample indexes",
        "> ",
        "train_index <- sample(1:nrow(dx), 0.8 * nrow(dx))",
        "> ",
        "test_index <- setdiff(1:nrow(dx), train_index)",
        "> ",
        "",
        "> ",
        "# Build X_train, y_train, X_test, y_test",
        "> ",
        "X_train <- dx[train_index, -12]",
        "> ",
        "y_train <- dx[train_index, \"stroke\"]",
        "> ",
        "",
        "> ",
        "X_test <- dx[test_index, -12]",
        "> ",
        "y_test <- dx[test_index, \"stroke\"]",
        "> ",
        "install.packages(\"DMwR\")",
        "Installing package into ‘/Users/tosi-n/Library/R/3.6/library’\n(as ‘lib’ is unspecified)\n",
        "also installing the dependencies ‘bitops’, ‘gtools’, ‘gdata’, ‘caTools’, ‘TTR’, ‘gplots’, ‘quantmod’, ‘abind’, ‘ROCR’\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/bitops_1.0-6.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 25079 bytes (24 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 24 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/gtools_3.8.1.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 318769 bytes (311 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 311 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/gdata_2.18.0.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 1223792 bytes (1.2 MB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 1.2 MB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/caTools_1.18.0.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 245973 bytes (240 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 240 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/TTR_0.23-6.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 518332 bytes (506 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 506 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/gplots_3.0.3.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 586572 bytes (572 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 572 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/quantmod_0.4-16.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 963704 bytes (941 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 941 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/abind_1.4-5.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 62240 bytes (60 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 60 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/ROCR_1.0-7.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 202195 bytes (197 KB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 197 KB\n\n",
        "trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.6/DMwR_0.4.1.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 3196326 bytes (3.0 MB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 3.0 MB\n\n",
        "\nThe downloaded binary packages are in\n\t/var/folders/1p/d4hfqy4d7kj4dl0jw737b9w00000gn/T//Rtmp9HQHJe/downloaded_packages\n",
        "> ",
        "getwd()",
        "[1] \"/Volumes/Loopdisk/Stroke-CPM\"\n",
        "> ",
        "library(reticulate)",
        "> ",
        "library(mice)",
        "> ",
        "library(tidyverse)",
        "> ",
        "library(ggplot2)",
        "> ",
        "library(MASS)",
        "> ",
        "library(stargazer)",
        "> ",
        "library(sjPlot)",
        "> ",
        "library(dataPreparation)",
        "> ",
        "library(DMwR)",
        "> ",
        "use_python(\"/Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\", required = TRUE)",
        "> ",
        "d <- read.csv(\"/Volumes/Loopdisk/Stroke-CPM/data/train_2v.csv\")",
        "> ",
        "reticulate::py_config()",
        "python:         /Volumes/Loopdisk/Dev/PyDsc/env/bin/python3\nlibpython:      /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/config-3.6m-darwin/libpython3.6.dylib\npythonhome:     /Library/Frameworks/Python.framework/Versions/3.6:/Library/Frameworks/Python.framework/Versions/3.6\nversion:        3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31)  [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\nnumpy:          /Volumes/Loopdisk/Dev/PyDsc/env/lib/python3.6/site-packages/numpy\nnumpy_version:  1.16.2\n\nNOTE: Python version was forced by use_python function\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke ~ ., dx, perc.over = 800, k = 5, perc.under = 200, learner = NULL)",
        "Error in T[i, ] : subscript out of bounds\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke, dx, perc.over = 800, k = 5, perc.under = 200, learner = NULL)",
        "Error in names(dn) <- dnn : attempt to set an attribute on NULL\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke, dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in names(dn) <- dnn : attempt to set an attribute on NULL\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke, dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in names(dn) <- dnn : attempt to set an attribute on NULL\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke ~ ., dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in T[i, ] : subscript out of bounds\n",
        "> ",
        "dx_ <- SMOTE(dx$stroke ~ ., dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in T[i, ] : subscript out of bounds\n",
        "> ",
        "dx_ <- SMOTE(stroke ~ ., dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in T[i, ] : subscript out of bounds\n",
        "> ",
        "dx_ <- SMOTE(stroke, dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in which(names(data) == as.character(form[[2]])) : \n  object 'stroke' not found\n",
        "> ",
        "dx_ <- SMOTE(stroke ~ ., dx, perc.over = 800, k = 5, perc.under = 200)",
        "Error in T[i, ] : subscript out of bounds\n",
        "> ",
        "dx_ <- SMOTE(stroke ~ ., dx, perc.over = 800, k = 20, perc.under = 200)",
        "Error in T[i, ] : subscript out of bounds\n",
        "\nRestarting R session...\n\n"
    ],
    "type" : [
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        2
    ]
}